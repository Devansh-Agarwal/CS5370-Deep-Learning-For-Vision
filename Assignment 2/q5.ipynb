{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "device = torch.device('cpu')\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the data by converting catagorical data to numerical values, filling missing values by median, scaling the data and the spliting it in test and train set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train.drop('Id',axis = 1, inplace = True)\n",
    "train = pd.get_dummies(train, dummy_na=True, drop_first=True)\n",
    "train.fillna(train.median(),inplace=True)\n",
    "trainLabels = train['SalePrice']\n",
    "train.drop('SalePrice',axis = 1, inplace = True)\n",
    "normalizer=MinMaxScaler()\n",
    "train=normalizer.fit_transform(train)\n",
    "XTrain, XTest, YTrain, YTest = train_test_split(train,trainLabels,test_size=0.2)\n",
    "labelBatches=np.split(YTrain,16)\n",
    "trainBatches=np.split(XTrain,16)\n",
    "for i in range(len(labelBatches)):\n",
    "    labelBatches[i] = torch.from_numpy(np.array(labelBatches[i])).float().view(-1, 1)\n",
    "    trainBatches[i] = torch.from_numpy(trainBatches[i]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model,trainBatches, labelBatches, epochs, lossCriterion):\n",
    "    print(len(trainBatches))\n",
    "    for e in range(1, epochs + 1):\n",
    "        trainLoss = 0\n",
    "        model.train()\n",
    "        for i in range(len(trainBatches)):\n",
    "            output = model(trainBatches[i])\n",
    "            loss = lossCriterion(torch.log(labelBatches[i]), torch.log(output))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            trainLoss += loss.item()\n",
    "        if (e)%25==0:\n",
    "            trainLoss = trainLoss/len(trainBatches)\n",
    "            print(\"Epoch: {}\".format(e), \"Training Loss: {:.5f}.. \".format(trainLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(model, XTest, YTest, criterion):\n",
    "    testLabels=torch.from_numpy(np.array(YTest)).float().view(-1, 1)\n",
    "    test = torch.from_numpy(XTest).float()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        output = model.forward(test)\n",
    "    loss=torch.sqrt(criterion(torch.log(testLabels), torch.log(output)))\n",
    "    print(\"RMSE Error={}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the top performing models have same architecture, this pyramid architecture performed better than the other random ones. Since it is a regression problem the outputs need to be merged into 1 at some point, instead of drastically reducing the layers, reducing them gradually is better. Relu activation was working better than sigmoid and tanh activations as Relu does not have saturation of gradients problem which generaly accelerates the convergence and it also introduces sparsity in the NN.<br />\n",
    "model1(error = 0.162) > model3(error = 0.183) > model2(0.344)<br />\n",
    "model1 is better than model3 as RMSProp only uses mean of 1st moments of gradient whereas adam uses the 2nd moments also Adam has been empirically proven to work better over other optimizers.<br />\n",
    "model3 is better than model2, Adam and RMSProp are very close, in model3 I introducded a weight_decay to Adam which deteriorates its performance. Weight_decay is useful when there is a lot of traing data but this is not the case here, weight_decay prevents over fitting but since there is not a lot of data it is hampering with learning. It penalizes model complexity but that is not required here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch: 25 Training Loss: 13.47132.. \n",
      "Epoch: 50 Training Loss: 1.86203.. \n",
      "Epoch: 75 Training Loss: 0.38459.. \n",
      "Epoch: 100 Training Loss: 0.13721.. \n",
      "Epoch: 125 Training Loss: 0.11786.. \n",
      "Epoch: 150 Training Loss: 0.10926.. \n",
      "Epoch: 175 Training Loss: 0.09996.. \n",
      "Epoch: 200 Training Loss: 0.09007.. \n",
      "Epoch: 225 Training Loss: 0.07970.. \n",
      "Epoch: 250 Training Loss: 0.06924.. \n",
      "Epoch: 275 Training Loss: 0.05939.. \n",
      "Epoch: 300 Training Loss: 0.05076.. \n",
      "Epoch: 325 Training Loss: 0.04370.. \n",
      "Epoch: 350 Training Loss: 0.03834.. \n",
      "Epoch: 375 Training Loss: 0.03440.. \n",
      "Epoch: 400 Training Loss: 0.03135.. \n",
      "Epoch: 425 Training Loss: 0.02881.. \n",
      "Epoch: 450 Training Loss: 0.02663.. \n",
      "Epoch: 475 Training Loss: 0.02471.. \n",
      "Epoch: 500 Training Loss: 0.02298.. \n",
      "Epoch: 525 Training Loss: 0.02138.. \n",
      "Epoch: 550 Training Loss: 0.01966.. \n",
      "Epoch: 575 Training Loss: 0.01798.. \n",
      "Epoch: 600 Training Loss: 0.01636.. \n",
      "Epoch: 625 Training Loss: 0.01482.. \n",
      "Epoch: 650 Training Loss: 0.01340.. \n",
      "Epoch: 675 Training Loss: 0.01205.. \n",
      "Epoch: 700 Training Loss: 0.01076.. \n",
      "RMSE Error=0.16289493441581726\n"
     ]
    }
   ],
   "source": [
    "model1 = torch.nn.Sequential(\n",
    "          torch.nn.Linear(288, 144),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(144, 72),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(72, 36),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(36, 18),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(18,9),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(9,1),\n",
    "          torch.nn.ReLU(),\n",
    "        )\n",
    "lossCriterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.001)  \n",
    "trainModel(model1, trainBatches, labelBatches, 700, lossCriterion)\n",
    "testModel(model1, XTest, YTest, lossCriterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch: 25 Training Loss: 103.25434.. \n",
      "Epoch: 50 Training Loss: 64.33721.. \n",
      "Epoch: 75 Training Loss: 45.42891.. \n",
      "Epoch: 100 Training Loss: 33.81724.. \n",
      "Epoch: 125 Training Loss: 25.73164.. \n",
      "Epoch: 150 Training Loss: 19.52944.. \n",
      "Epoch: 175 Training Loss: 14.49879.. \n",
      "Epoch: 200 Training Loss: 10.68226.. \n",
      "Epoch: 225 Training Loss: 7.89629.. \n",
      "Epoch: 250 Training Loss: 5.77809.. \n",
      "Epoch: 275 Training Loss: 4.11671.. \n",
      "Epoch: 300 Training Loss: 2.85576.. \n",
      "Epoch: 325 Training Loss: 1.92507.. \n",
      "Epoch: 350 Training Loss: 1.25678.. \n",
      "Epoch: 375 Training Loss: 0.80480.. \n",
      "Epoch: 400 Training Loss: 0.50424.. \n",
      "Epoch: 425 Training Loss: 0.31141.. \n",
      "Epoch: 450 Training Loss: 0.19335.. \n",
      "Epoch: 475 Training Loss: 0.14009.. \n",
      "Epoch: 500 Training Loss: 0.12089.. \n",
      "Epoch: 525 Training Loss: 0.11488.. \n",
      "Epoch: 550 Training Loss: 0.11150.. \n",
      "Epoch: 575 Training Loss: 0.10809.. \n",
      "Epoch: 600 Training Loss: 0.10428.. \n",
      "Epoch: 625 Training Loss: 0.10002.. \n",
      "Epoch: 650 Training Loss: 0.09531.. \n",
      "Epoch: 675 Training Loss: 0.09016.. \n",
      "Epoch: 700 Training Loss: 0.08464.. \n",
      "RMSE Error=0.344946026802063\n"
     ]
    }
   ],
   "source": [
    "model2 = torch.nn.Sequential(\n",
    "          torch.nn.Linear(288, 144),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(144, 72),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(72, 36),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(36, 18),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(18,9),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(9,1),\n",
    "          torch.nn.ReLU(),\n",
    "        )\n",
    "lossCriterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "trainModel(model2, trainBatches, labelBatches, 700, lossCriterion)\n",
    "testModel(model2, XTest, YTest, lossCriterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch: 25 Training Loss: 72.20291.. \n",
      "Epoch: 50 Training Loss: 37.09581.. \n",
      "Epoch: 75 Training Loss: 19.40721.. \n",
      "Epoch: 100 Training Loss: 9.68485.. \n",
      "Epoch: 125 Training Loss: 4.28616.. \n",
      "Epoch: 150 Training Loss: 1.48195.. \n",
      "Epoch: 175 Training Loss: 0.32120.. \n",
      "Epoch: 200 Training Loss: 0.11842.. \n",
      "Epoch: 225 Training Loss: 0.10228.. \n",
      "Epoch: 250 Training Loss: 0.08762.. \n",
      "Epoch: 275 Training Loss: 0.07437.. \n",
      "Epoch: 300 Training Loss: 0.06261.. \n",
      "Epoch: 325 Training Loss: 0.05270.. \n",
      "Epoch: 350 Training Loss: 0.04507.. \n",
      "Epoch: 375 Training Loss: 0.03989.. \n",
      "Epoch: 400 Training Loss: 0.03653.. \n",
      "Epoch: 425 Training Loss: 0.03404.. \n",
      "Epoch: 450 Training Loss: 0.03194.. \n",
      "Epoch: 475 Training Loss: 0.03011.. \n",
      "Epoch: 500 Training Loss: 0.02851.. \n",
      "Epoch: 525 Training Loss: 0.02708.. \n",
      "Epoch: 550 Training Loss: 0.02582.. \n",
      "Epoch: 575 Training Loss: 0.02468.. \n",
      "Epoch: 600 Training Loss: 0.02367.. \n",
      "Epoch: 625 Training Loss: 0.02275.. \n",
      "Epoch: 650 Training Loss: 0.02193.. \n",
      "Epoch: 675 Training Loss: 0.02118.. \n",
      "Epoch: 700 Training Loss: 0.02051.. \n",
      "RMSE Error=0.18346016108989716\n"
     ]
    }
   ],
   "source": [
    "model3 = torch.nn.Sequential(\n",
    "          torch.nn.Linear(288, 144),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(144, 72),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(72, 36),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(36, 18),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(18,9),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(9,1),\n",
    "          torch.nn.ReLU(),\n",
    "        )\n",
    "optimizer = torch.optim.RMSprop(model3.parameters(),lr=1e-4,alpha = 0.98)\n",
    "lossCriterion = torch.nn.MSELoss() \n",
    "trainModel(model3, trainBatches, labelBatches, 700, lossCriterion)\n",
    "testModel(model3, XTest, YTest, lossCriterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some of the other stuff I tried"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch: 25 Training Loss: 148.05813.. \n",
      "Epoch: 50 Training Loss: 145.94094.. \n",
      "Epoch: 75 Training Loss: 145.34897.. \n",
      "Epoch: 100 Training Loss: 145.07745.. \n",
      "Epoch: 125 Training Loss: 144.93084.. \n",
      "Epoch: 150 Training Loss: 144.85369.. \n",
      "Epoch: 175 Training Loss: 144.80767.. \n",
      "Epoch: 200 Training Loss: 144.77781.. \n",
      "Epoch: 225 Training Loss: 144.75728.. \n",
      "Epoch: 250 Training Loss: 144.74262.. \n",
      "Epoch: 275 Training Loss: 144.73182.. \n",
      "Epoch: 300 Training Loss: 144.72371.. \n",
      "Epoch: 325 Training Loss: 144.71747.. \n",
      "Epoch: 350 Training Loss: 144.71265.. \n",
      "Epoch: 375 Training Loss: 144.70886.. \n",
      "Epoch: 400 Training Loss: 144.70586.. \n",
      "Epoch: 425 Training Loss: 144.70348.. \n",
      "Epoch: 450 Training Loss: 144.70157.. \n",
      "Epoch: 475 Training Loss: 144.70002.. \n",
      "Epoch: 500 Training Loss: 144.69879.. \n",
      "Epoch: 525 Training Loss: 144.69778.. \n",
      "Epoch: 550 Training Loss: 144.69697.. \n",
      "Epoch: 575 Training Loss: 144.69631.. \n",
      "Epoch: 600 Training Loss: 144.69577.. \n",
      "Epoch: 625 Training Loss: 144.69533.. \n",
      "Epoch: 650 Training Loss: 144.69496.. \n",
      "Epoch: 675 Training Loss: 144.69468.. \n",
      "Epoch: 700 Training Loss: 144.69444.. \n",
      "RMSE Error=12.038020133972168\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(288, 144),\n",
    "          torch.nn.Sigmoid(),\n",
    "          torch.nn.Linear(144, 72),\n",
    "          torch.nn.Sigmoid(),\n",
    "          torch.nn.Linear(72, 36),\n",
    "          torch.nn.Sigmoid(),\n",
    "          torch.nn.Linear(36, 18),\n",
    "          torch.nn.Sigmoid(),\n",
    "          torch.nn.Linear(18,9),\n",
    "          torch.nn.Sigmoid(),\n",
    "          torch.nn.Linear(9,1),\n",
    "          torch.nn.Sigmoid(),\n",
    "        )\n",
    "lossCriterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "trainModel(model, trainBatches, labelBatches, 700, lossCriterion)\n",
    "testModel(model, XTest, YTest, lossCriterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanh activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Epoch: 25 Training Loss: 145.06855.. \n",
      "Epoch: 50 Training Loss: 144.83309.. \n",
      "Epoch: 75 Training Loss: 144.76731.. \n",
      "Epoch: 100 Training Loss: 144.73894.. \n",
      "Epoch: 125 Training Loss: 144.72393.. \n",
      "Epoch: 150 Training Loss: 144.71498.. \n",
      "Epoch: 175 Training Loss: 144.70921.. \n",
      "Epoch: 200 Training Loss: 144.70528.. \n",
      "Epoch: 225 Training Loss: 144.70249.. \n",
      "Epoch: 250 Training Loss: 144.70046.. \n",
      "Epoch: 275 Training Loss: 144.69893.. \n",
      "Epoch: 300 Training Loss: 144.69777.. \n",
      "Epoch: 325 Training Loss: 144.69688.. \n",
      "Epoch: 350 Training Loss: 144.69618.. \n",
      "Epoch: 375 Training Loss: 144.69562.. \n",
      "Epoch: 400 Training Loss: 144.69519.. \n",
      "Epoch: 425 Training Loss: 144.69484.. \n",
      "Epoch: 450 Training Loss: 144.69456.. \n",
      "Epoch: 475 Training Loss: 144.69434.. \n",
      "Epoch: 500 Training Loss: 144.69415.. \n",
      "Epoch: 525 Training Loss: 144.69400.. \n",
      "Epoch: 550 Training Loss: 144.69388.. \n",
      "Epoch: 575 Training Loss: 144.69379.. \n",
      "Epoch: 600 Training Loss: 144.69370.. \n",
      "Epoch: 625 Training Loss: 144.69365.. \n",
      "Epoch: 650 Training Loss: 144.69358.. \n",
      "Epoch: 675 Training Loss: 144.69354.. \n",
      "Epoch: 700 Training Loss: 144.69352.. \n",
      "RMSE Error=12.037981986999512\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(288, 144),\n",
    "          torch.nn.Tanh(),\n",
    "          torch.nn.Linear(144, 72),\n",
    "          torch.nn.Tanh(),\n",
    "          torch.nn.Linear(72, 36),\n",
    "          torch.nn.Tanh(),\n",
    "          torch.nn.Linear(36, 18),\n",
    "          torch.nn.Tanh(),\n",
    "          torch.nn.Linear(18,9),\n",
    "          torch.nn.Tanh(),\n",
    "          torch.nn.Linear(9,1),\n",
    "          torch.nn.Tanh(),\n",
    "        )\n",
    "lossCriterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "trainModel(model, trainBatches, labelBatches, 700, lossCriterion)\n",
    "testModel(model, XTest, YTest, lossCriterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnv",
   "language": "python",
   "name": "pytorchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
